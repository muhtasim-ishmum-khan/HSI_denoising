{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ac6f4d-2304-41bf-8e93-2bf5e2bb0f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import gc\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from einops import rearrange\n",
    "import random\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchmetrics.image import StructuralSimilarityIndexMeasure\n",
    "\n",
    "# Import custom modules (assumed to be in the same directory)\n",
    "from Conv3d_patch import SpectralSpatialConv3D\n",
    "from gssa_attention_module import GSSA\n",
    "from dense3D import ResidualConv3DProgressiveRefinement\n",
    "\n",
    "# def free_gpu_memory():\n",
    "#     \"\"\"Force clear GPU memory in PyTorch (especially useful in Jupyter).\"\"\"\n",
    "#     gc.collect()                      # Clear Python garbage\n",
    "#     torch.cuda.empty_cache()          # Clear PyTorch cache\n",
    "#     torch.cuda.ipc_collect()          # Collect inter-process memory (helps in Jupyter)\n",
    "#     print(\"GPU memory cleared.\")\n",
    "\n",
    "# Call this at the start of your script / cell\n",
    "free_gpu_memory()\n",
    "\n",
    "def spectral_angle_mapper(y_true, y_pred, eps=1e-8):\n",
    "    \"\"\"Compute Spectral Angle Mapper (SAM) loss between true and predicted spectra.\"\"\"\n",
    "    y_true_norm = y_true / (torch.norm(y_true, dim=-1, keepdim=True) + eps)\n",
    "    y_pred_norm = y_pred / (torch.norm(y_pred, dim=-1, keepdim=True) + eps)\n",
    "    cos_sim = torch.clamp(torch.sum(y_true_norm * y_pred_norm, dim=-1), -1.0, 1.0)\n",
    "    sam = torch.acos(cos_sim).mean()\n",
    "    return sam\n",
    "\n",
    "def compute_psnr(y_true, y_pred, max_pixel=None):\n",
    "    \"\"\"Compute Peak Signal-to-Noise Ratio (PSNR).\"\"\"\n",
    "    # Validate max_pixel based on input data range\n",
    "    if max_pixel is None:\n",
    "        max_pixel = torch.max(torch.abs(y_true)).item()\n",
    "        if max_pixel == 0:\n",
    "            max_pixel = 1.0  # Fallback to 1.0 if data range is zero\n",
    "    mse = torch.mean((y_true - y_pred) ** 2)\n",
    "    if mse == 0:\n",
    "        return 100.0  # Return large finite value instead of inf\n",
    "    return 20 * torch.log10(max_pixel / torch.sqrt(mse)).item()\n",
    "\n",
    "def compute_ssim(y_true, y_pred, device, data_range=1.0):\n",
    "    \"\"\"Compute Structural Similarity Index (SSIM).\"\"\"\n",
    "    ssim_metric = StructuralSimilarityIndexMeasure(data_range=data_range).to(device)\n",
    "    return ssim_metric(y_true, y_pred).item()\n",
    "\n",
    "def compute_sam_np(y_true, y_pred, eps=1e-8):\n",
    "    \"\"\"Compute SAM metric for numpy arrays.\"\"\"\n",
    "    y_true_norm = y_true / (np.linalg.norm(y_true, axis=-1, keepdims=True) + eps)\n",
    "    y_pred_norm = y_pred / (np.linalg.norm(y_pred, axis=-1, keepdims=True) + eps)\n",
    "    cos_sim = np.clip(np.sum(y_true_norm * y_pred_norm, axis=-1), -1.0, 1.0)\n",
    "    sam = np.mean(np.arccos(cos_sim))\n",
    "    return sam\n",
    "\n",
    "class HSIDenoisingDataset(Dataset):\n",
    "    \"\"\"Dataset for HSI denoising with normalization and augmentation.\"\"\"\n",
    "    \n",
    "    def __init__(self, noisy_patches, clean_patches, augment=True, flip_prob=0.5, shuffle_prob=0.3):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            noisy_patches: Tensor of shape (N, 1, H, W, D) - noisy input patches\n",
    "            clean_patches: Tensor of shape (N, 1, H, W, D) - clean ground truth patches\n",
    "            augment: Whether to apply data augmentation\n",
    "            flip_prob: Probability of spatial flips\n",
    "            shuffle_prob: Probability of spectral band shuffling\n",
    "        \"\"\"\n",
    "        self.noisy_patches = noisy_patches\n",
    "        self.clean_patches = clean_patches\n",
    "        self.augment = augment\n",
    "        self.flip_prob = flip_prob\n",
    "        self.shuffle_prob = shuffle_prob\n",
    "        \n",
    "        # Validate dimensions\n",
    "        assert noisy_patches.shape == clean_patches.shape, \\\n",
    "            f\"Shape mismatch: noisy {noisy_patches.shape} vs clean {clean_patches.shape}\"\n",
    "        \n",
    "        # Normalize patches to [0, 1]\n",
    "        self.noisy_patches = self._normalize(self.noisy_patches)\n",
    "        self.clean_patches = self._normalize(self.clean_patches)\n",
    "    \n",
    "    def _normalize(self, patches):\n",
    "        \"\"\"Normalize patches to [0, 1] using min-max scaling.\"\"\"\n",
    "        min_val = torch.amin(patches, dim=(0, 1, 2, 3), keepdim=True)\n",
    "        max_val = torch.amax(patches, dim=(0, 1, 2, 3), keepdim=True)\n",
    "        return (patches - min_val) / (max_val - min_val + 1e-8)\n",
    "    \n",
    "    def _augment(self, noisy, clean):\n",
    "        \"\"\"Apply data augmentation: spatial flips and spectral band shuffling.\"\"\"\n",
    "        if not self.augment:\n",
    "            return noisy, clean\n",
    "        \n",
    "        # Random horizontal flip\n",
    "        if random.random() < self.flip_prob:\n",
    "            noisy = torch.flip(noisy, dims=[2])\n",
    "            clean = torch.flip(clean, dims=[2])\n",
    "        \n",
    "        # Random vertical flip\n",
    "        if random.random() < self.flip_prob:\n",
    "            noisy = torch.flip(noisy, dims=[3])\n",
    "            clean = torch.flip(clean, dims=[3])\n",
    "        \n",
    "        # Random spectral band shuffling\n",
    "        if random.random() < self.shuffle_prob:\n",
    "            indices = torch.randperm(noisy.shape[-1])\n",
    "            noisy = noisy[..., indices]\n",
    "            clean = clean[..., indices]\n",
    "        \n",
    "        return noisy, clean\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.noisy_patches)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        noisy, clean = self.noisy_patches[idx], self.clean_patches[idx]\n",
    "        if self.augment:\n",
    "            noisy, clean = self._augment(noisy, clean)\n",
    "        return noisy, clean\n",
    "\n",
    "class HSIDenoisingPipeline(nn.Module):\n",
    "    \"\"\"Complete HSI Denoising Pipeline combining Conv3D, GSSA, and Dense3D.\"\"\"\n",
    "    \n",
    "    def __init__(self, conv3d_channels=64, spectral_bands=191, dropout=0.1, use_residual=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            conv3d_channels: Number of channels in Conv3D feature extractor\n",
    "            spectral_bands: Number of spectral bands\n",
    "            dropout: Dropout rate\n",
    "            use_residual: Whether to add residual connection to input\n",
    "        \"\"\"\n",
    "        super(HSIDenoisingPipeline, self).__init__()\n",
    "        self.use_residual = use_residual\n",
    "        \n",
    "        # Stage 1: Conv3D Feature Extraction\n",
    "        self.conv3d_extractor = SpectralSpatialConv3D(\n",
    "            in_channels=1, \n",
    "            out_channels=conv3d_channels, \n",
    "            dropout=0.1\n",
    "        )\n",
    "        \n",
    "        # Stage 2: GSSA Attention Mechanism\n",
    "        self.gssa_attention = GSSA(\n",
    "            channel=conv3d_channels,\n",
    "            num_bands=spectral_bands,\n",
    "            flex=False\n",
    "        )\n",
    "        \n",
    "        # Stage 3: Progressive Refinement and Denoising\n",
    "        self.progressive_denoiser = ResidualConv3DProgressiveRefinement(\n",
    "            in_channels=conv3d_channels,\n",
    "            out_channels=1,\n",
    "            dropout=dropout,\n",
    "            use_groupnorm=True\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the pipeline.\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor of shape (B, 1, H, W, D) - noisy HSI patches\n",
    "            \n",
    "        Returns:\n",
    "            denoised: Output tensor of shape (B, 1, H, W, D) - denoised patches\n",
    "            attention_maps: Attention weights from GSSA\n",
    "        \"\"\"\n",
    "        # Stage 1: Conv3D Feature Extraction\n",
    "        conv3d_features = self.conv3d_extractor(x)  # (B, C, H, W, D)\n",
    "        \n",
    "        # Stage 2: GSSA Attention Processing\n",
    "        gssa_features, attention_maps = self.gssa_attention(conv3d_features)  # (B, C, H, W, D)\n",
    "        \n",
    "        # Stage 3: Progressive Refinement\n",
    "        denoised, aggregated = self.progressive_denoiser(conv3d_features, gssa_features)  # (B, 1, H, W, D)\n",
    "        \n",
    "        # Residual connection\n",
    "        if self.use_residual:\n",
    "            denoised = x + denoised\n",
    "        \n",
    "        return denoised, attention_maps, aggregated\n",
    "\n",
    "class HSIDenoisingTrainer:\n",
    "    \"\"\"Complete HSI Denoising Training Pipeline.\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 noisy_mat_path,\n",
    "                 clean_mat_path,\n",
    "                 device='auto',\n",
    "                 learning_rate=1e-3,\n",
    "                 batch_size=4,\n",
    "                 num_epochs=1,\n",
    "                 patch_key='patches',\n",
    "                 clean_patch_key='patches',\n",
    "                 save_dir='./trained_models',\n",
    "                 conv3d_channels=64,\n",
    "                 dropout=0.1,\n",
    "                 mse_weight=1.0,\n",
    "                 sam_weight=0.1,\n",
    "                 early_stopping_patience=20,\n",
    "                 val_split=0.2):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            noisy_mat_path: Path to noisy patches .mat file\n",
    "            clean_mat_path: Path to clean patches .mat file\n",
    "            device: 'auto', 'cuda', 'mps', or 'cpu'\n",
    "            learning_rate: Initial learning rate\n",
    "            batch_size: Batch size for training\n",
    "            num_epochs: Number of training epochs\n",
    "            patch_key: Key for noisy patches in .mat file\n",
    "            clean_patch_key: Key for clean patches in .mat file\n",
    "            save_dir: Directory to save models and results\n",
    "            conv3d_channels: Number of Conv3D channels\n",
    "            dropout: Dropout rate\n",
    "            mse_weight: Weight for MSE loss\n",
    "            sam_weight: Weight for SAM loss\n",
    "            early_stopping_patience: Epochs to wait for validation loss improvement\n",
    "            val_split: Fraction of data to use for validation\n",
    "        \"\"\"\n",
    "        self.noisy_mat_path = noisy_mat_path\n",
    "        self.clean_mat_path = clean_mat_path\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "        self.patch_key = patch_key\n",
    "        self.clean_patch_key = clean_patch_key\n",
    "        self.save_dir = save_dir\n",
    "        self.conv3d_channels = conv3d_channels\n",
    "        self.dropout = dropout\n",
    "        self.mse_weight = mse_weight\n",
    "        self.sam_weight = sam_weight\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.val_split = val_split\n",
    "        \n",
    "        # Set device\n",
    "        self.device = self._setup_device(device)\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        \n",
    "        # Initialize components\n",
    "        self.model = None\n",
    "        self.optimizer = None\n",
    "        self.scheduler = None\n",
    "        self.criterion_mse = None\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.patience_counter = 0\n",
    "        self.current_lr = self.learning_rate\n",
    "        \n",
    "        # Create save directory\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    def _setup_device(self, device):\n",
    "        \"\"\"Setup computation device.\"\"\"\n",
    "        if device == 'auto':\n",
    "            if torch.cuda.is_available():\n",
    "                return torch.device('cuda')\n",
    "            elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "                return torch.device('mps')\n",
    "            else:\n",
    "                return torch.device('cpu')\n",
    "        else:\n",
    "            return torch.device(device)\n",
    "    \n",
    "    def load_patches(self):\n",
    "        \"\"\"Load and preprocess patches from .mat files with lazy loading support.\"\"\"\n",
    "        print(\"Loading patches...\")\n",
    "        \n",
    "        def load_mat_patches(mat_path, key):\n",
    "            try:\n",
    "                data = sio.loadmat(mat_path)\n",
    "                if key in data:\n",
    "                    patches = data[key]\n",
    "                else:\n",
    "                    possible_keys = ['patches', 'data', 'patch_data', 'hsi_patches']\n",
    "                    found_key = None\n",
    "                    for k in possible_keys:\n",
    "                        if k in data:\n",
    "                            found_key = k\n",
    "                            break\n",
    "                    if found_key:\n",
    "                        patches = data[found_key]\n",
    "                        print(f\"Found patches under key: '{found_key}' in {mat_path}\")\n",
    "                    else:\n",
    "                        available_keys = [k for k in data.keys() if not k.startswith('__')]\n",
    "                        raise KeyError(f\"Key '{key}' not found. Available: {available_keys}\")\n",
    "                \n",
    "                print(f\"Loaded patches shape: {patches.shape}\")\n",
    "                return patches\n",
    "            except Exception as e:\n",
    "                raise RuntimeError(f\"Error loading {mat_path}: {e}\")\n",
    "        \n",
    "        # Load patches\n",
    "        noisy_patches = load_mat_patches(self.noisy_mat_path, self.patch_key)\n",
    "        clean_patches = load_mat_patches(self.clean_mat_path, self.clean_patch_key)\n",
    "        \n",
    "        # Validate shapes\n",
    "        if noisy_patches.shape != clean_patches.shape:\n",
    "            raise ValueError(f\"Shape mismatch: noisy {noisy_patches.shape} vs clean {clean_patches.shape}\")\n",
    "        \n",
    "        # Convert to tensor\n",
    "        def process_patches(patches):\n",
    "            if len(patches.shape) == 4:\n",
    "                if patches.shape[-1] < patches.shape[1]:  # spectral dimension is last\n",
    "                    patches = np.transpose(patches, (0, 3, 1, 2))\n",
    "                tensor = torch.from_numpy(patches).float().unsqueeze(1)  # (N, 1, H, W, D)\n",
    "                return tensor\n",
    "            else:\n",
    "                raise ValueError(f\"Expected 4D patch array, got shape: {patches.shape}\")\n",
    "        \n",
    "        noisy_tensor = process_patches(noisy_patches)\n",
    "        clean_tensor = process_patches(clean_patches)\n",
    "        \n",
    "        print(f\"Processed tensor shapes: {noisy_tensor.shape}\")\n",
    "        \n",
    "        # Validate tensors\n",
    "        for name, tensor in [(\"Noisy\", noisy_tensor), (\"Clean\", clean_tensor)]:\n",
    "            if torch.isnan(tensor).any():\n",
    "                raise ValueError(f\"{name} tensor contains NaN values\")\n",
    "            if torch.isinf(tensor).any():\n",
    "                raise ValueError(f\"{name} tensor contains infinite values\")\n",
    "            print(f\"{name} - min: {tensor.min():.4f}, max: {tensor.max():.4f}\")\n",
    "        \n",
    "        return noisy_tensor, clean_tensor\n",
    "    \n",
    "    def initialize_model(self, sample_input):\n",
    "        \"\"\"Initialize the pipeline model.\"\"\"\n",
    "        print(\"Initializing HSI Denoising Pipeline...\")\n",
    "        \n",
    "        # Get dimensions\n",
    "        batch_size, channels, height, width, spectral_bands = sample_input.shape\n",
    "        print(f\"Input dimensions: B={batch_size}, C={channels}, H={height}, W={width}, D={spectral_bands}\")\n",
    "        \n",
    "        # Initialize pipeline\n",
    "        self.model = HSIDenoisingPipeline(\n",
    "            conv3d_channels=self.conv3d_channels,\n",
    "            spectral_bands=spectral_bands,\n",
    "            dropout=self.dropout,\n",
    "            use_residual=True\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Test forward pass\n",
    "        with torch.no_grad():\n",
    "            test_input = sample_input[:1].to(self.device)\n",
    "            test_output, test_attention = self.model(test_input)\n",
    "            print(f\"Pipeline test - Input: {test_input.shape}, Output: {test_output.shape}\")\n",
    "            print(f\"Attention maps shape: {test_attention.shape}\")\n",
    "        \n",
    "        print(\"Pipeline initialized successfully!\")\n",
    "    \n",
    "    def setup_training(self):\n",
    "        \"\"\"Setup optimizer, scheduler, and loss functions.\"\"\"\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        self.scheduler = ReduceLROnPlateau(self.optimizer, mode='min', factor=0.5, patience=5)\n",
    "        self.criterion_mse = nn.MSELoss()\n",
    "        print(f\"Training setup - Optimizer: Adam, LR: {self.learning_rate}, Loss: MSE+SAM\")\n",
    "    \n",
    "    def train_epoch(self, dataloader, is_train=True):\n",
    "        \"\"\"Train or validate for one epoch.\"\"\"\n",
    "        mode = 'train' if is_train else 'val'\n",
    "        self.model.train() if is_train else self.model.eval()\n",
    "        epoch_loss = 0.0\n",
    "        epoch_mse = 0.0\n",
    "        epoch_sam = 0.0\n",
    "        num_batches = 0\n",
    "        \n",
    "        with torch.set_grad_enabled(is_train):\n",
    "            for noisy_batch, clean_batch in dataloader:\n",
    "                noisy_batch = noisy_batch.to(self.device)\n",
    "                clean_batch = clean_batch.to(self.device)\n",
    "                \n",
    "                if is_train:\n",
    "                    self.optimizer.zero_grad()\n",
    "                \n",
    "                denoised_output, _ = self.model(noisy_batch)\n",
    "                \n",
    "                mse_loss = self.criterion_mse(denoised_output, clean_batch)\n",
    "                sam_loss = spectral_angle_mapper(clean_batch, denoised_output)\n",
    "                loss = self.mse_weight * mse_loss + self.sam_weight * sam_loss\n",
    "                \n",
    "                if is_train:\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "                \n",
    "                epoch_loss += loss.item()\n",
    "                epoch_mse += mse_loss.item()\n",
    "                epoch_sam += sam_loss.item()\n",
    "                num_batches += 1\n",
    "                \n",
    "                if self.device.type == 'cuda':\n",
    "                    torch.cuda.empty_cache()\n",
    "        \n",
    "        avg_loss = epoch_loss / num_batches\n",
    "        avg_mse = epoch_mse / num_batches\n",
    "        avg_sam = epoch_sam / num_batches\n",
    "        return avg_loss, avg_mse, avg_sam\n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"Main training loop with validation.\"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        print(\"Starting HSI Denoising Pipeline Training\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Load data\n",
    "        noisy_patches, clean_patches = self.load_patches()\n",
    "        \n",
    "        # Initialize model\n",
    "        self.initialize_model(noisy_patches)\n",
    "        \n",
    "        # Setup training\n",
    "        self.setup_training()\n",
    "        \n",
    "        # Create dataset\n",
    "        dataset = HSIDenoisingDataset(noisy_patches, clean_patches, augment=True)\n",
    "        \n",
    "        # Train/validation split\n",
    "        dataset_size = len(dataset)\n",
    "        indices = list(range(dataset_size))\n",
    "        random.shuffle(indices)\n",
    "        split = int(self.val_split * dataset_size)\n",
    "        train_indices, val_indices = indices[split:], indices[:split]\n",
    "        \n",
    "        train_sampler = SubsetRandomSampler(train_indices)\n",
    "        val_sampler = SubsetRandomSampler(val_indices)\n",
    "        \n",
    "        train_loader = DataLoader(dataset, batch_size=self.batch_size, sampler=train_sampler, \n",
    "                                num_workers=min(os.cpu_count(), 4), pin_memory=True)\n",
    "        val_loader = DataLoader(dataset, batch_size=self.batch_size, sampler=val_sampler, \n",
    "                              num_workers=min(os.cpu_count(), 4), pin_memory=True)\n",
    "        \n",
    "        print(f\"Training Configuration:\")\n",
    "        print(f\"  - Dataset size: {len(dataset)} patches\")\n",
    "        print(f\"  - Train/Val split: {len(train_indices)}/{len(val_indices)}\")\n",
    "        print(f\"  - Batch size: {self.batch_size}\")\n",
    "        print(f\"  - Number of epochs: {self.num_epochs}\")\n",
    "        print(f\"  - Learning rate: {self.learning_rate}\")\n",
    "        print(f\"  - MSE/SAM weights: {self.mse_weight}/{self.sam_weight}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        # Training loop\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for epoch in range(self.num_epochs):\n",
    "            epoch_start_time = time.time()\n",
    "            \n",
    "            # Train\n",
    "            train_loss, train_mse, train_sam = self.train_epoch(train_loader, is_train=True)\n",
    "            self.train_losses.append(train_loss)\n",
    "            \n",
    "            # Validate\n",
    "            val_loss, val_mse, val_sam = self.train_epoch(val_loader, is_train=False)\n",
    "            self.val_losses.append(val_loss)\n",
    "            \n",
    "            # Update learning rate\n",
    "            self.scheduler.step(val_loss)\n",
    "            current_lr = self.optimizer.param_groups[0]['lr']\n",
    "            if current_lr != self.current_lr:\n",
    "                print(f\"Learning rate reduced to {current_lr:.6f}\")\n",
    "                self.current_lr = current_lr\n",
    "            \n",
    "            # Save best model\n",
    "            if val_loss < self.best_val_loss:\n",
    "                self.best_val_loss = val_loss\n",
    "                self.save_checkpoint(epoch + 1, is_best=True)\n",
    "                self.patience_counter = 0\n",
    "            else:\n",
    "                self.patience_counter += 1\n",
    "            \n",
    "            # Print progress\n",
    "            epoch_time = time.time() - epoch_start_time\n",
    "            elapsed_time = time.time() - start_time\n",
    "            print(f\"Epoch [{epoch+1:3d}/{self.num_epochs}] | \"\n",
    "                  f\"Train Loss: {train_loss:.6f} (MSE: {train_mse:.6f}, SAM: {train_sam:.6f}) | \"\n",
    "                  f\"Val Loss: {val_loss:.6f} (MSE: {val_mse:.6f}, SAM: {val_sam:.6f}) | \"\n",
    "                  f\"Time: {epoch_time:.2f}s | \"\n",
    "                  f\"Total: {elapsed_time/60:.1f}min\")\n",
    "            \n",
    "            # Save checkpoint every 10 epochs\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                self.save_checkpoint(epoch + 1)\n",
    "            \n",
    "            # Early stopping\n",
    "            if self.patience_counter >= self.early_stopping_patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "                break\n",
    "            \n",
    "            # Memory cleanup\n",
    "            if (epoch + 1) % 5 == 0:\n",
    "                gc.collect()\n",
    "                if self.device.type == 'cuda':\n",
    "                    torch.cuda.empty_cache()\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        print(\"-\" * 60)\n",
    "        print(f\"Training completed in {total_time/60:.2f} minutes\")\n",
    "        print(f\"Final train loss: {self.train_losses[-1]:.6f}\")\n",
    "        print(f\"Best val loss: {self.best_val_loss:.6f}\")\n",
    "        \n",
    "        # Compute PSNR, SSIM, and SAM on validation set\n",
    "        self.model.eval()\n",
    "        val_psnr = []\n",
    "        val_ssim = []\n",
    "        val_sam = []\n",
    "        with torch.no_grad():\n",
    "            for noisy_batch, clean_batch in val_loader:\n",
    "                noisy_batch = noisy_batch.to(self.device)\n",
    "                clean_batch = clean_batch.to(self.device)\n",
    "                denoised_output, _ = self.model(noisy_batch)\n",
    "                val_psnr.append(compute_psnr(clean_batch, denoised_output))\n",
    "                val_ssim.append(compute_ssim(clean_batch, denoised_output, self.device))\n",
    "                val_sam.append(spectral_angle_mapper(clean_batch, denoised_output).item())\n",
    "        \n",
    "        avg_psnr = np.mean(val_psnr)\n",
    "        avg_ssim = np.mean(val_ssim)\n",
    "        avg_sam = np.mean(val_sam)\n",
    "        print(f\"Validation Metrics:\")\n",
    "        print(f\"  PSNR: {avg_psnr:.2f} dB\")\n",
    "        print(f\"  SSIM: {avg_ssim:.4f}\")\n",
    "        print(f\"  SAM: {avg_sam:.4f} radians\")\n",
    "        \n",
    "        # Save metrics\n",
    "        np.save(f\"{self.save_dir}/final_metrics.npy\", {\n",
    "            'psnr': avg_psnr,\n",
    "            'ssim': avg_ssim,\n",
    "            'sam': avg_sam,\n",
    "            'train_losses': np.array(self.train_losses),\n",
    "            'val_losses': np.array(self.val_losses)\n",
    "        })\n",
    "        \n",
    "        # Save final model\n",
    "        self.save_model()\n",
    "        \n",
    "        return self.train_losses, self.val_losses, avg_psnr, avg_ssim, avg_sam\n",
    "    \n",
    "    def save_checkpoint(self, epoch, is_best=False):\n",
    "        \"\"\"Save training checkpoint.\"\"\"\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'train_losses': self.train_losses,\n",
    "            'val_losses': self.val_losses,\n",
    "        }\n",
    "        path = f\"{self.save_dir}/checkpoint_epoch_{epoch}.pth\"\n",
    "        if is_best:\n",
    "            path = f\"{self.save_dir}/best_model.pth\"\n",
    "        torch.save(checkpoint, path)\n",
    "        print(f\"{'Best model' if is_best else 'Checkpoint'} saved at {path}\")\n",
    "    \n",
    "    def save_model(self):\n",
    "        \"\"\"Save final trained model.\"\"\"\n",
    "        torch.save(self.model.state_dict(), f\"{self.save_dir}/hsi_denoising_pipeline.pth\")\n",
    "        np.save(f\"{self.save_dir}/training_losses.npy\", np.array(self.train_losses))\n",
    "        np.save(f\"{self.save_dir}/validation_losses.npy\", np.array(self.val_losses))\n",
    "        print(f\"Final model saved to {self.save_dir}\")\n",
    "    \n",
    "    def load_model(self, model_path):\n",
    "        \"\"\"Load a trained model.\"\"\"\n",
    "        if self.model is None:\n",
    "            raise RuntimeError(\"Model not initialized. Call initialize_model() first.\")\n",
    "        self.model.load_state_dict(torch.load(model_path, map_location=self.device))\n",
    "        print(f\"Model loaded from {model_path}\")\n",
    "    \n",
    "    def denoise_patches(self, input_patches, output_path=\"denoised_patches.mat\"):\n",
    "        \"\"\"Apply trained model to denoise patches.\"\"\"\n",
    "        self.model.eval()\n",
    "        dataset = HSIDenoisingDataset(input_patches, input_patches, augment=False)\n",
    "        dataloader = DataLoader(dataset, batch_size=self.batch_size, shuffle=False, \n",
    "                              num_workers=min(os.cpu_count(), 4), pin_memory=True)\n",
    "        \n",
    "        denoised_patches = []\n",
    "        attention_maps = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (noisy_batch, _) in enumerate(dataloader):\n",
    "                noisy_batch = noisy_batch.to(self.device)\n",
    "                denoised_output, batch_attention = self.model(noisy_batch)\n",
    "                denoised_patches.append(denoised_output.cpu())\n",
    "                attention_maps.append(batch_attention.cpu())\n",
    "                print(f\"Processed batch {batch_idx + 1}/{len(dataloader)}\")\n",
    "        \n",
    "        denoised_patches = torch.cat(denoised_patches, dim=0)\n",
    "        attention_maps = torch.cat(attention_maps, dim=0)\n",
    "        \n",
    "        print(f\"Debug - Combined denoised shape: {denoised_patches.shape}\")\n",
    "        \n",
    "        # Convert to numpy: (B, 1, H, W, D) -> (B, H, W, D)\n",
    "        denoised_numpy = denoised_patches.squeeze(1).numpy()\n",
    "        attention_numpy = attention_maps.numpy()\n",
    "        \n",
    "        print(f\"Debug - Final denoised numpy shape: {denoised_numpy.shape}\")\n",
    "        \n",
    "        sio.savemat(output_path, {\n",
    "            'denoised_patches': denoised_numpy,\n",
    "            'attention_maps': attention_numpy\n",
    "        })\n",
    "        \n",
    "        print(f\"Denoised patches saved to: {output_path}\")\n",
    "        return denoised_numpy, attention_numpy\n",
    "\n",
    "    def visualize_pipeline(self, sample_index=0, save_path=None):\n",
    "        \"\"\"\n",
    "        Visualize the full HSI denoising pipeline stages on one sample patch:\n",
    "        clean patch -> noisy patch -> conv3d features -> GSSA features -> denoised patch.\n",
    "        \"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "        import numpy as np\n",
    "        \n",
    "        # Load patches (assuming they're tensors: [N, 1, H, W, D])\n",
    "        noisy_patches, clean_patches = self.load_patches()\n",
    "        \n",
    "        # Select sample and move to device\n",
    "        sample_clean = clean_patches[sample_index].unsqueeze(0).to(self.device)  # (1,1,H,W,D)\n",
    "        sample_noisy = noisy_patches[sample_index].unsqueeze(0).to(self.device)  # (1,1,H,W,D)\n",
    "        \n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            # Conv3D feature extraction (output shape: (1, C, H, W, D))\n",
    "            conv3d_features = self.model.conv3d_extractor(sample_noisy)\n",
    "            \n",
    "            # GSSA attention features (output shape: (1, C, H, W, D))\n",
    "            gssa_features, attention_maps = self.model.gssa_attention(conv3d_features)\n",
    "            \n",
    "            # Denoised patch (output shape: (1, 1, H, W, D))\n",
    "            denoised, aggregated = self.model.progressive_denoiser(conv3d_features, gssa_features)\n",
    "            if self.model.use_residual:\n",
    "                denoised = sample_noisy + denoised\n",
    "        \n",
    "        # Convert tensors to numpy arrays (remove batch and channel dims)\n",
    "        sample_clean_np = sample_clean.squeeze(0).squeeze(0).cpu().numpy()   # (H,W,D)\n",
    "        sample_noisy_np = sample_noisy.squeeze(0).squeeze(0).cpu().numpy()   # (H,W,D)\n",
    "        conv3d_np = conv3d_features.squeeze(0).cpu().numpy()                 # (C,H,W,D)\n",
    "        gssa_np = gssa_features.squeeze(0).cpu().numpy()                     # (C,H,W,D)\n",
    "        denoised_np = denoised.squeeze(0).squeeze(0).cpu().numpy()           # (H,W,D)\n",
    "        aggregated_np = aggregated.squeeze(0).cpu().numpy()   \n",
    "        \n",
    "        # Choose band index for visualization\n",
    "        band_idx = 20\n",
    "        max_band = sample_clean_np.shape[2] - 1\n",
    "        if band_idx > max_band:\n",
    "            band_idx = max_band\n",
    "        \n",
    "        # For Conv3D and GSSA features, select a representative channel or mean over channels at band_idx\n",
    "        # Here, we average over channels at band_idx slice\n",
    "        conv3d_feature_map = conv3d_np[:, :, :, band_idx].mean(axis=0)  # shape: (H,W)\n",
    "        gssa_feature_map = gssa_np[:, :, :, band_idx].mean(axis=0)      # shape: (H,W)\n",
    "        aggregated_feature_map = aggregated_np[:,:,:,band_idx].mean(axis=0)\n",
    "        \n",
    "        def show_img(ax, img, title):\n",
    "            im = ax.imshow(img, cmap='viridis')\n",
    "            ax.set_title(title)\n",
    "            ax.axis('off')\n",
    "            plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "        \n",
    "        # Plot layout: 1 row, 5 columns\n",
    "        fig, axs = plt.subplots(1, 6, figsize=(24, 8))\n",
    "        \n",
    "        show_img(axs[0], sample_clean_np[:, :, band_idx], f'Clean Patch\\n(Band {band_idx})')\n",
    "        show_img(axs[1], sample_noisy_np[:, :, band_idx], f'Noisy Patch\\n(Band {band_idx})')\n",
    "        show_img(axs[2], conv3d_feature_map, f'Conv3D Features\\n(mean over channels, Band {band_idx})')\n",
    "        show_img(axs[3], gssa_feature_map, f'GSSA Features\\n(mean over channels, Band {band_idx})')\n",
    "        show_img(axs[4], aggregated_feature_map[:, :, band_idx], f'aggregated feature map of \\nConv3D and GSSA\\n(Band {band_idx})')\n",
    "        show_img(axs[5], denoised_np[:, :, band_idx], f'Denoised Patch\\n(Band {band_idx})')\n",
    "        \n",
    "        \n",
    "        plt.tight_layout()\n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "            print(f\"Visualization saved at: {save_path}\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "    def plot_training_curve(self):\n",
    "        \"\"\"Plot training and validation loss curves.\"\"\"\n",
    "        if not self.train_losses or not self.val_losses:\n",
    "            print(\"No training history available\")\n",
    "            return\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        # Main loss curve\n",
    "        plt.subplot(2, 1, 1)\n",
    "        plt.plot(self.train_losses, 'b-', label='Training Loss')\n",
    "        plt.plot(self.val_losses, 'r-', label='Validation Loss')\n",
    "        plt.title('HSI Denoising Loss Over Time', fontsize=14)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss (MSE+SAM)')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Log scale\n",
    "        plt.subplot(2, 1, 2)\n",
    "        plt.semilogy(self.train_losses, 'b-', label='Training Loss (Log Scale)')\n",
    "        plt.semilogy(self.val_losses, 'r-', label='Validation Loss (Log Scale)')\n",
    "        plt.title('Loss (Log Scale)', fontsize=14)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss (Log Scale)')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{self.save_dir}/training_curve.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        # Print statistics\n",
    "        min_train_loss = min(self.train_losses)\n",
    "        min_val_loss = min(self.val_losses)\n",
    "        min_train_epoch = self.train_losses.index(min_train_loss) + 1\n",
    "        min_val_epoch = self.val_losses.index(min_val_loss) + 1\n",
    "        \n",
    "        print(f\"\\nTraining Statistics:\")\n",
    "        print(f\"  Minimum Train Loss: {min_train_loss:.6f} at epoch {min_train_epoch}\")\n",
    "        print(f\"  Minimum Val Loss: {min_val_loss:.6f} at epoch {min_val_epoch}\")\n",
    "        print(f\"  Final Train Loss: {self.train_losses[-1]:.6f}\")\n",
    "        print(f\"  Final Val Loss: {self.val_losses[-1]:.6f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    config = {\n",
    "        'noisy_mat_path': '/Users/muhtasimishmumkhan/Desktop/499/hsi/hybArch/HSI_denoising/init/noisy_patches/train_Wash2_patches_noisy.mat',\n",
    "        'clean_mat_path': '/Users/muhtasimishmumkhan/Desktop/499/hsi/hybArch/HSI_denoising/saved_patches/train_Wash2_patches.mat',\n",
    "        'device': 'auto',\n",
    "        'learning_rate': 1e-3,\n",
    "        'batch_size': 4,\n",
    "        'num_epochs': 1,\n",
    "        'patch_key': 'patches',\n",
    "        'clean_patch_key': 'patches',\n",
    "        'save_dir': './hsi_pipeline_models',\n",
    "        'conv3d_channels': 64,\n",
    "        'dropout': 0.1,\n",
    "        'mse_weight': 1.0,\n",
    "        'sam_weight': 0.1,\n",
    "        'early_stopping_patience': 20,\n",
    "        'val_split': 0.2\n",
    "    }\n",
    "    \n",
    "    # Initialize and train\n",
    "    trainer = HSIDenoisingTrainer(**config)\n",
    "    train_losses, val_losses, final_psnr, final_ssim, final_sam = trainer.train()\n",
    "    \n",
    "    # Post-training analysis\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Starting Post-Training Analysis\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Plot training curve\n",
    "    trainer.plot_training_curve()\n",
    "    # Visualize the denoising pipeline for a sample patch\n",
    "    trainer.visualize_pipeline(sample_index=0, save_path=f\"{config['save_dir']}/pipeline_visualization.png\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Analysis Complete! Generated Files:\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Models: {config['save_dir']}/hsi_denoising_pipeline.pth\")\n",
    "    print(f\"Best model: {config['save_dir']}/best_model.pth\")\n",
    "    print(f\"Training curve: {config['save_dir']}/training_curve.png\")\n",
    "    print(f\"Final metrics: {config['save_dir']}/final_metrics.npy\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"Training and analysis completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch-env)",
   "language": "python",
   "name": "torch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
